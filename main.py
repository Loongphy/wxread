# main.py ä¸»é€»è¾‘ï¼šåŒ…æ‹¬å­—æ®µæ‹¼æ¥ã€æ¨¡æ‹Ÿè¯·æ±‚
import re
import json
import time
import random
import logging
import hashlib
import requests
import urllib.parse
from push import push
from config import data, headers, cookies, READ_NUM, PUSH_METHOD, book, chapter

# é…ç½®æ—¥å¿—æ ¼å¼
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)-8s - %(message)s')

# åŠ å¯†ç›åŠå…¶å®ƒé»˜è®¤å€¼
KEY = "3c5c8717f3daf09iop3423zafeqoi"
COOKIE_DATA = {"rq": "%2Fweb%2Fbook%2Fread"}
READ_URL = "https://weread.qq.com/web/book/read"
RENEW_URL = "https://weread.qq.com/web/login/renewal"
FIX_SYNCKEY_URL = "https://weread.qq.com/web/book/chapterInfos"


def encode_data(data):
    """æ•°æ®ç¼–ç """
    return '&'.join(f"{k}={urllib.parse.quote(str(data[k]), safe='')}" for k in sorted(data.keys()))


def cal_hash(input_string):
    """è®¡ç®—å“ˆå¸Œå€¼"""
    _7032f5 = 0x15051505
    _cc1055 = _7032f5
    length = len(input_string)
    _19094e = length - 1

    while _19094e > 0:
        _7032f5 = 0x7fffffff & (_7032f5 ^ ord(input_string[_19094e]) << (length - _19094e) % 30)
        _cc1055 = 0x7fffffff & (_cc1055 ^ ord(input_string[_19094e - 1]) << _19094e % 30)
        _19094e -= 2

    return hex(_7032f5 + _cc1055)[2:].lower()

def get_wr_skey():
    """åˆ·æ–°cookieå¯†é’¥"""
    response = requests.post(RENEW_URL, headers=headers, cookies=cookies,
                             data=json.dumps(COOKIE_DATA, separators=(',', ':')))
    for cookie in response.headers.get('Set-Cookie', '').split(';'):
        if "wr_skey" in cookie:
            return cookie.split('=')[-1][:8]
    return None

def fix_no_synckey():
    requests.post(FIX_SYNCKEY_URL, headers=headers, cookies=cookies,
                             data=json.dumps({"bookIds":["3300060341"]}, separators=(',', ':')))

def refresh_cookie():
    logging.info(f"ğŸª åˆ·æ–°cookie")
    new_skey = get_wr_skey()
    if new_skey:
        cookies['wr_skey'] = new_skey
        logging.info(f"âœ… å¯†é’¥åˆ·æ–°æˆåŠŸï¼Œæ–°å¯†é’¥ï¼š{new_skey}")
        logging.info(f"ğŸ”„ é‡æ–°æœ¬æ¬¡é˜…è¯»ã€‚")
    else:
        ERROR_CODE = "âŒ æ— æ³•è·å–æ–°å¯†é’¥æˆ–è€…WXREAD_CURL_BASHé…ç½®æœ‰è¯¯ï¼Œç»ˆæ­¢è¿è¡Œã€‚"
        logging.error(ERROR_CODE)
        push(ERROR_CODE, PUSH_METHOD)
        raise Exception(ERROR_CODE)

refresh_cookie()
index = 1
MAX_FAIL_RETRY = 3 # å¤±è´¥é‡è¯•æ¬¡æ•°
lastTime = int(time.time()) - 30
logging.info(f"â±ï¸ ä¸€å…±éœ€è¦é˜…è¯» {READ_NUM} æ¬¡...")


while index <= READ_NUM:
    data.pop('s')
    data['b'] = random.choice(book)
    data['c'] = random.choice(chapter)
    thisTime = int(time.time())
    data['ct'] = thisTime
    data['rt'] = thisTime - lastTime
    data['ts'] = int(thisTime * 1000) + random.randint(0, 1000)
    data['rn'] = random.randint(0, 1000)
    data['sg'] = hashlib.sha256(f"{data['ts']}{data['rn']}{KEY}".encode()).hexdigest()
    data['s'] = cal_hash(encode_data(data))

    logging.info(f"â±ï¸ å°è¯•ç¬¬ {index} æ¬¡é˜…è¯»...")
    logging.info(f"ğŸ“• data: {data}")
    response = requests.post(READ_URL, headers=headers, cookies=cookies, data=json.dumps(data, separators=(',', ':')))
    resData = response.json()
    logging.info(f"ğŸ“• response: {resData}")

    # ---- æ–°çš„å¤±è´¥é‡è¯•é€»è¾‘å¼€å§‹ ----
    if 'succ' not in resData:
        logging.warning("âŒ æœªè¿”å› succï¼Œè¿›å…¥é‡è¯•é˜¶æ®µâ€¦")
        retry = 0
        while retry < MAX_FAIL_RETRY:
            retry += 1
            logging.info(f"ğŸ” é‡è¯• #{retry}ï¼šrefresh_cookie -> POST")
            try:
                refresh_cookie()
            except Exception:
                # refresh_cookie å†…éƒ¨å·² push + æ‰“æ—¥å¿—ï¼›è¿™é‡Œç›´æ¥åˆ¤å®šå¤±è´¥ç»ˆæ­¢è„šæœ¬
                logging.error("âŒ refresh_cookie æŠ›å¼‚å¸¸ï¼Œç»ˆæ­¢è„šæœ¬ã€‚")
                raise

            # é‡å‘è¯·æ±‚ï¼ˆæ— éœ€æ”¹åŠ¨ data çš„ç­¾åæ—¶é—´æˆ³ä¹Ÿå¯ä»¥ç»§ç»­ç”¨ï¼›å¦‚éœ€æ›´ä¸¥è°¨å¯é‡ç®—ä¸€æ¬¡ ts/rn/sg/sï¼‰
            response = requests.post(READ_URL, headers=headers, cookies=cookies,
                                     data=json.dumps(data, separators=(',', ':')))
            try:
                resData = response.json()
            except Exception:
                resData = {}

            logging.info(f"ğŸ“• retry response: {resData}")

            # é‡è¯•é€€å‡ºæ¡ä»¶
            if 'succ' in resData:
                logging.info("âœ… é‡è¯•æˆåŠŸï¼Œå‡ºç° succï¼Œé€€å‡ºé‡è¯•é˜¶æ®µã€‚")
                break

            # ä»æœªæˆåŠŸï¼šç­‰å¾… 2 ç§’å†ä¸‹ä¸€æ¬¡é‡è¯•
            logging.info(f"â³ 2s åç»§ç»­é‡è¯•â€¦")
            time.sleep(2)

        # è¶…è¿‡ MAX_FAIL_RETRY æ¬¡ä»æ—  succ => è®¡ä¸ºå¤±è´¥å¹¶ç»ˆæ­¢è„šæœ¬
        if 'succ' not in resData:
            err = f"âŒ æœ¬æ¬¡é˜…è¯»åœ¨é‡è¯• {MAX_FAIL_RETRY} æ¬¡åä»æœªè¿”å› succï¼Œè®¡ä¸ºå¤±è´¥å¹¶ç»ˆæ­¢ã€‚"
            logging.error(err)
            push(err, PUSH_METHOD)
            break
    # ---- æ–°çš„å¤±è´¥é‡è¯•é€»è¾‘ç»“æŸ ----

    # æœ‰ succ çš„æ­£å¸¸åˆ†æ”¯
    if 'synckey' in resData:
        lastTime = thisTime
        index += 1
        logging.info(f"âœ… é˜…è¯»æˆåŠŸï¼Œé˜…è¯»è¿›åº¦ï¼š{(index - 1) * 0.5} åˆ†é’Ÿ")
        time.sleep(30)
    else:
        logging.warning("âŒ è¿”å› succ ä½†æ—  synckeyï¼Œå°è¯•ä¿®å¤â€¦")
        fix_no_synckey()

logging.info("ğŸ‰ é˜…è¯»è„šæœ¬å·²å®Œæˆï¼")

if PUSH_METHOD not in (None, ''):
    logging.info("â±ï¸ å¼€å§‹æ¨é€...")
    push(f"ğŸ‰ å¾®ä¿¡è¯»ä¹¦è‡ªåŠ¨é˜…è¯»å®Œæˆï¼\nâ±ï¸ é˜…è¯»æ—¶é•¿ï¼š{(index - 1) * 0.5}åˆ†é’Ÿã€‚", PUSH_METHOD)
